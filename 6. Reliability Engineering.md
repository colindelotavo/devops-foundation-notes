# Engineering doesn't end with deployment
Reliability engineering is a crucial part of DevOps that aims to ensure a system functions properly under specific conditions for a set duration. This practice area covers aspects such as performance, availability, and security. Software problems are now responsible for most outages and production problems, rather than infrastructure issues. Design for operation and operate for design are two critical areas to consider when addressing reliability. Google popularised the term 'site reliability engineering', which involves product teams supporting their services until they reach a certain level of maturity, with development teams handling 5% of the operational workload ongoing, which promotes a healthy feedback loop.

# Design for operation: Theory
Design for operation involves making decisions at the beginning of the pipeline that can help your application work well even in adverse conditions. This approach involves using design patterns that address stability, such as the circuit breaker, to prevent cascading outages caused by integration point failures. The [12 factor app](https://12factor.net/) manifesto provides guidelines for producing service-ready software, including separating runtime configuration from app code.

# Design for operation: Practice
it's important to acknowledge that all systems fail and pushing more money towards highly available systems is not the solution. Instead, embracing deliberate adversity, such as using the Chaos Monkey tool to intentionally cause failure, can lead to fundamentally different approaches to system design. Operational processes must depend on as few integration points as possible, and understanding how to draw an X through any dependency of the system is critical. Performance can also be improved through the use of code profilers and application performance management (APM) tools, and running baselines on every build in your CI pipeline is crucial to your service's health.

# Operate for design: Metrics and monitoring
## 1. Service performance and uptime
This is the highest level of monitoring and is often referred to as synthetic checks. These checks answer the question of whether the service or application is working or not. Synthetic checks are not real traffic or real customers, but are simulations of various scenarios that the service might encounter.
## 2. Software component metrics
This is monitoring that is done on ports or processes, usually located on the host. This layer of monitoring is one level deeper than service performance and uptime, and answers the question of whether a particular host or process is working or not.
## 3. System metrics
These are time-series metrics that can be anything from CPU or memory usage to disk I/O. System metrics help answer the question of whether a service, host, or process is functioning normally.
## 4. Application metrics
These are telemetry from the application that gives insight into what the application is actually doing. Examples of application metrics include the time it takes for a certain function call to complete, the number of logins in the last hour, or the count of all the error events that have happened. These metrics are often custom and specific to the application being monitored.
## 5. Performance 
Performance metrics are tied through all the previous types of metrics, and provide insights into the performance of the application or service. Application performance monitoring (APM) and real user monitoring (RUM) are two common types of performance monitoring. APM isolates function performance at the code level, while RUM uses front-end instrumentation to capture the performance observed by the users of the system
## 6. Security
Security monitoring includes four key areas: system, application security, custom events in the application, and anomalies. System security includes monitoring for bad TLS/SSL settings, open ports, and other system configuration issues. Application security involves detecting when XSS or SQL injection attacks are attempted. Custom events in the application, such as password resets, invalid logins, or new account creations, can also provide insights into potential security issues. Anomalies, such as HTTP 401 errors or access attempts from irregular IP segments, can also be indicators of security threats.

# Operate for design: Logging
## 1. Don't collect log data you won't use
Don't collect log data that you have no use for. Only log what you need to investigate outages or audit something in the future.
## 2. Keep logs for as long as they can be used
Retain log data for as long as you might need it or as long as it is prescribed by regulations. Keeping too much log data can be costly in terms of resources and maintenance.
## 3. Alert only on what you must respond to
Log all you can, but only alert your team based on critical problems like customer experience or security issues. Clearly define your log levels to make it easy to filter and prioritize logs.
## 4. Don't exceed business security needs
Don't overbuild capacity or defense in your logging system. Keep it lean and meet business needs.
## 5. Logs change
Logs can change in format or messages when new versions of software are released. Encourage everyone to take ownership of their logs in the centralized logging system and create a feedback loop to ensure everyone is aware of the changes.

# Your SRE toolchain
Monitoring tools include the likes of Nagios, Zabbix, Datadog, Netuitive, Ruxit, and Librato; open-source tools like StatsD, Ganglia, Graphite, and Grafana; log management tools like Splunk, Sumo Logic, Logentries, and ELK stack; incident management tools like PagerDuty, VictorOps, and Flapjack; status page tools like Statuspage.io; command dispatchers like Rundeck, SaltStack, and Ansible; and security monitoring tools. 
Note: As with other mentioned toolchains, it is normal and even preferrable at times to write your own tools.